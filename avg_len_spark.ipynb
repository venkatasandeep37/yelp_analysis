{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdcfb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8020aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "import re\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "from pyspark import sql\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import avg, col, isnan, when, count, length\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, IDF,Tokenizer, CountVectorizer, CountVectorizer,StringIndexer,StopWordsRemover\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d9a918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/28 00:29:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/11/28 00:29:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/11/28 00:29:48 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/11/28 00:29:48 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/11/28 00:29:48 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/11/28 00:29:48 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf = conf)\n",
    "spark = SparkSession(sc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab447f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/28 00:29:50 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "## creating sparksession and giving an app name\n",
    "spark = SparkSession(sc).builder.appName('sparkdf').getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "686f8013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('yelp_review.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54fe1546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "import re\n",
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "from pyspark import sql\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import avg, col, isnan, when, count, length\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, IDF,Tokenizer, CountVectorizer, CountVectorizer,StringIndexer,StopWordsRemover\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6dea77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/28 00:33:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/11/28 00:33:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/11/28 00:33:43 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/11/28 00:33:43 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/11/28 00:33:43 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/11/28 00:33:43 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()\n",
    "sqlContext = sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90ee7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"csv\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option('multiLine', True).option(\"encoding\", \"ISO-8859-1\").option(\"header\", \"true\").load(\"yelp_review.csv\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "647270a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|stars|  avg(text_length)|\n",
      "+-----+------------------+\n",
      "|    1| 764.3232375714932|\n",
      "|    2|  769.430789139152|\n",
      "|    3| 716.4650379134368|\n",
      "|    4| 631.6703599070069|\n",
      "|    5|492.96431264248247|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Rating wise Avg_Len \n",
    "df1=df.select(col(\"stars\"),length(col(\"text\")).alias(\"Text_Length\")).groupBy(\"stars\").avg(\"text_length\").alias(\"Avg_Length\").sort(\"stars\")\n",
    "df1.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43a37de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+----------+---------+\n",
      "|stars|sum(useful)|sum(funny)|sum(cool)|\n",
      "+-----+-----------+----------+---------+\n",
      "|    1|    1616952|    517287|   204448|\n",
      "|    2|     712279|    292800|   182066|\n",
      "|    3|     825371|    378463|   397658|\n",
      "|    4|    1651213|    694321|  1008809|\n",
      "|    5|    2482043|    796350|  1290839|\n",
      "+-----+-----------+----------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#useful, funny, cool\n",
    "df= df.withColumn(\"useful\",col(\"useful\").cast(\"int\"))\n",
    "df = df.withColumn(\"funny\",col(\"funny\").cast(\"int\"))\n",
    "df = df.withColumn(\"cool\",col(\"cool\").cast(\"int\"))\n",
    "df = df.select(\"stars\",\"useful\",\"funny\",\"cool\").groupBy(\"stars\").sum(\"useful\",\"funny\",\"cool\").sort(\"stars\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015610a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08654150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
