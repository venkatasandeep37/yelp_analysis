{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2bbddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbbcaf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark import SparkConf\n",
    "import re\n",
    "import pyspark.sql.functions as func\n",
    "#from pyspark.ml.feature import Tokenizer, HashingTF, IDF \n",
    "#from pyspark.ml.classification import LogisticRegression\n",
    "#from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, IDF,Tokenizer, CountVectorizer, CountVectorizer,StringIndexer,StopWordsRemover\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.classification import SVMModel, SVMWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors as MLLibVectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import * \n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2c61c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local[*]\").set(\"spark.executer.memory\", \"2g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df83a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/28 03:13:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/11/28 03:13:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/11/28 03:13:43 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/11/28 03:13:43 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/11/28 03:13:43 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/11/28 03:13:43 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/11/28 03:13:43 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "22/11/28 03:13:43 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
      "22/11/28 03:13:43 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=conf)\n",
    "#spark = SparkSession(sc)\n",
    "spark = SparkSession(sc).builder.getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507b5b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id_rev: string (nullable = true)\n",
      " |-- stars_rev: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: string (nullable = true)\n",
      " |-- funny: string (nullable = true)\n",
      " |-- cool: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+---------+----------+--------------------+------+-----+----+\n",
      "|           review_id|             user_id|     business_id_rev|stars_rev|      date|                text|useful|funny|cool|\n",
      "+--------------------+--------------------+--------------------+---------+----------+--------------------+------+-----+----+\n",
      "|vkVSCC7xljjrAI4UG...|bv2nCi5Qv5vroFiqK...|AEx2SYEUJmTxVVB18...|        5|2016-05-28|Super simple plac...|     0|    0|   0|\n",
      "|n6QzIUObkYshz4dz2...|bv2nCi5Qv5vroFiqK...|VR6GpWIda3SfvPC-l...|        5|2016-05-28|Small unassuming ...|     0|    0|   0|\n",
      "|MV3CcKScW05u5LVfF...|bv2nCi5Qv5vroFiqK...|CKC0-MOWMqoeWf6s-...|        5|2016-05-28|Lester's is locat...|     0|    0|   0|\n",
      "|IXvOzsEMYtiJI0CAR...|bv2nCi5Qv5vroFiqK...|ACFtxLv8pGrrxMm6E...|        4|2016-05-28|Love coming here....|     0|    0|   0|\n",
      "|L_9BTb55X0GDtThi6...|bv2nCi5Qv5vroFiqK...|s2I_Ni76bjJNK9yG6...|        4|2016-05-28|Had their chocola...|     0|    0|   0|\n",
      "|HRPm3vEZ_F-33TYVT...|_4iMDXbXZ1p1ONG29...|8QWPlVQ6D-OExqXoa...|        5|2014-09-24|Cycle Pub Las Veg...|     1|    0|   0|\n",
      "|ymAUG8DZfQcFTBSOi...|u0LXt3Uea_GidxRW1...|9_CGhHMz8698M9-Pk...|        4|2012-05-11|Who would have gu...|     0|    0|   2|\n",
      "|8UIishPUD92hXtScS...|u0LXt3Uea_GidxRW1...|gkCorLgPyQLsptTHa...|        4|2015-10-27|Always drove past...|     1|    0|   0|\n",
      "|w41ZS9shepfO3uEyh...|u0LXt3Uea_GidxRW1...|5r6-G9C4YLbC7Ziz5...|        3|2013-02-09|Not bad!! Love th...|     1|    0|   0|\n",
      "|WF_QTN3p-thD74hqp...|u0LXt3Uea_GidxRW1...|fDF_o2JPU8BR1Gya-...|        5|2016-04-06|Love this place!\\...|     3|    0|   0|\n",
      "|PIsUSmvaUWB00qv5K...|u0LXt3Uea_GidxRW1...|z8oIoCT1cXz7gZP5G...|        4|2013-05-01|This is currently...|     1|    0|   0|\n",
      "|PdZ_uFjbbkjtm3SCY...|u0LXt3Uea_GidxRW1...|XWTPNfskXoUL-Lf32...|        3|2011-09-28|Server was a litt...|     5|    0|   1|\n",
      "|x5oV6wm9_Pb1QQ6jk...|u0LXt3Uea_GidxRW1...|13nKUHH-uEUXVZylg...|        1|2011-02-16|I thought Tidy's ...|     9|    0|   1|\n",
      "|lsoSqIrrDbQvWpMvs...|u0LXt3Uea_GidxRW1...|RtUvSWO_UZ8V3Wpj0...|        3|2012-12-03|Wanted to check o...|     2|    1|   1|\n",
      "|23eqwlZzCWZkADWfd...|u0LXt3Uea_GidxRW1...|Aov96CM4FZAXeZvKt...|        5|2010-07-16|This place is awe...|     2|    0|   1|\n",
      "|FunI9om-aK5oMIIJm...|u0LXt3Uea_GidxRW1...|0W4lkclzZThpx3V65...|        4|2011-09-28|a must stop when ...|     0|    0|   0|\n",
      "|FKu4iU62EmWT6GZXP...|u0LXt3Uea_GidxRW1...|fdnNZMk1NP7ZhL-YM...|        1|2012-10-23|I too have been t...|     0|    0|   0|\n",
      "|xdu8nXrbNKeaywCX7...|u0LXt3Uea_GidxRW1...|PFPUMF38-lraKzLcT...|        3|2010-09-15|Came here with my...|     2|    0|   0|\n",
      "|K7o5jDInfmX3cY5oH...|u0LXt3Uea_GidxRW1...|oWTn2IzrprsRkPfUL...|        3|2012-09-23|Came here for a b...|     4|    0|   0|\n",
      "|WYDFJOBOl7cycd7gN...|u0LXt3Uea_GidxRW1...|zgQHtqX0gqMw1nlBZ...|        1|2012-10-30|really excited to...|     9|    2|   1|\n",
      "+--------------------+--------------------+--------------------+---------+----------+--------------------+------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\"review_id\",\"user_id\",\"business_id\",\"stars\",\"date\",\"text\",\"useful\",\"funny\",\"cool\"\n",
    "\n",
    "#1. Clean the dataset\n",
    "\n",
    "yelp_rev = spark.read.format(\"csv\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option('multiLine', True).option(\"encoding\", \"ISO-8859-1\").option(\"header\", \"true\").load(\"yelp_review.csv\")\n",
    "yelp_rev = yelp_rev.withColumnRenamed(\"business_id\",\"business_id_rev\")\n",
    "yelp_rev = yelp_rev.withColumnRenamed(\"stars\",\"stars_rev\")\n",
    "yelp_rev.printSchema()\n",
    "yelp_rev.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bbc8f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id_biz: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- neighborhood: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- stars_biz: string (nullable = true)\n",
      " |-- review_count: string (nullable = true)\n",
      " |-- is_open: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yelp_biz = spark.read.format(\"csv\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option('multiLine', True).option(\"encoding\", \"ISO-8859-1\").option(\"header\", \"true\").load(\"yelp_business.csv\")\n",
    "yelp_biz = yelp_biz.withColumnRenamed(\"business_id\",\"business_id_biz\")\n",
    "yelp_biz = yelp_biz.withColumnRenamed(\"stars\",\"stars_biz\")\n",
    "yelp_biz.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8238c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---------+----------+--------------------+------+-----+----+--------------------+--------------------+------------+--------------------+---------+-----+-----------+---------+----------+---------+------------+-------+--------------------+\n",
      "|           review_id|             user_id|     business_id_rev|stars_rev|      date|                text|useful|funny|cool|     business_id_biz|                name|neighborhood|             address|     city|state|postal_code| latitude| longitude|stars_biz|review_count|is_open|          categories|\n",
      "+--------------------+--------------------+--------------------+---------+----------+--------------------+------+-----+----+--------------------+--------------------+------------+--------------------+---------+-----+-----------+---------+----------+---------+------------+-------+--------------------+\n",
      "|KEAHrqN-1DV0gmuNH...|xP1IYu2eGfxMWV9tj...|--9e1ONYQuAa-CB_R...|        5|2011-08-24|As part of a birt...|     1|    0|   0|--9e1ONYQuAa-CB_R...|\"Delmonico Steakh...|   The Strip|\"3355 Las Vegas B...|Las Vegas|   NV|      89109|36.123183|-115.16919|      4.0|        1451|      1|Cajun/Creole;Stea...|\n",
      "|6SgvNWJltnZhW7duJ...|oFyOUOeGTRZhFPF9u...|--9e1ONYQuAa-CB_R...|        5|2016-03-31|This is mine and ...|     0|    0|   0|--9e1ONYQuAa-CB_R...|\"Delmonico Steakh...|   The Strip|\"3355 Las Vegas B...|Las Vegas|   NV|      89109|36.123183|-115.16919|      4.0|        1451|      1|Cajun/Creole;Stea...|\n",
      "|iwx6s6yQxc7yjS7NF...|2aeNFntqY2QDZLADN...|--9e1ONYQuAa-CB_R...|        4|2015-06-29|Nice atmosphere a...|     0|    0|   0|--9e1ONYQuAa-CB_R...|\"Delmonico Steakh...|   The Strip|\"3355 Las Vegas B...|Las Vegas|   NV|      89109|36.123183|-115.16919|      4.0|        1451|      1|Cajun/Creole;Stea...|\n",
      "|UVUMu_bELdA56Ryfb...|gmPP4YFrgYsYQqPYo...|--9e1ONYQuAa-CB_R...|        5|2015-03-16|Every year a grou...|     1|    0|   0|--9e1ONYQuAa-CB_R...|\"Delmonico Steakh...|   The Strip|\"3355 Las Vegas B...|Las Vegas|   NV|      89109|36.123183|-115.16919|      4.0|        1451|      1|Cajun/Creole;Stea...|\n",
      "|Jjz9W-wBkoBoMcB8Z...|9bxdPvAhP6cuipD5s...|--9e1ONYQuAa-CB_R...|        5|2011-12-20|We had early rese...|     9|    7|   8|--9e1ONYQuAa-CB_R...|\"Delmonico Steakh...|   The Strip|\"3355 Las Vegas B...|Las Vegas|   NV|      89109|36.123183|-115.16919|      4.0|        1451|      1|Cajun/Creole;Stea...|\n",
      "+--------------------+--------------------+--------------------+---------+----------+--------------------+------+-----+----+--------------------+--------------------+------------+--------------------+---------+-----+-----------+---------+----------+---------+------------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "biz_rev = yelp_rev.join(yelp_biz,yelp_biz.business_id_biz ==  yelp_rev.business_id_rev,\"inner\")#.show(truncate=False)\n",
    "biz_rev.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd5e515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_rev.createOrReplaceTempView(\"final_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8055c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[review_id: string, user_id: string, business_id_rev: string, stars_rev: string, date: string, text: string, useful: string, funny: string, cool: string, business_id_biz: string, name: string, neighborhood: string, address: string, city: string, state: string, postal_code: string, latitude: string, longitude: string, stars_biz: string, review_count: string, is_open: string, categories: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin = spark.sql(\"select * from final_df where upper(name) like '%RESTAURANT%'\")\n",
    "\n",
    "fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec99fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = fin.select(\"review_id\",\"user_id\",\"business_id_rev\",\"stars_rev\",\"text\",\"useful\",\"funny\",\"cool\",\"categories\",\"state\",\"city\",\"categories\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5adc88cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin1 =  fin.withColumn(\"stars_rev_double\", fin[\"stars_rev\"].cast(\"double\"))\n",
    "\n",
    "\n",
    "#df3 = df.withColumn(\"new_gender\", expr(\"CASE WHEN gender = 'M' THEN 'Male' \" + \"WHEN gender = 'F' THEN 'Female' WHEN gender IS NULL THEN ''\" +\"ELSE gender END\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46d70d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---------+----------+--------------------+------+-----+----+--------------------+--------------------+------------+--------------------+---------+-----+-----------+-------------+--------------+---------+------------+-------+--------------------+----------------+-----+\n",
      "|           review_id|             user_id|     business_id_rev|stars_rev|      date|                text|useful|funny|cool|     business_id_biz|                name|neighborhood|             address|     city|state|postal_code|     latitude|     longitude|stars_biz|review_count|is_open|          categories|stars_rev_double|label|\n",
      "+--------------------+--------------------+--------------------+---------+----------+--------------------+------+-----+----+--------------------+--------------------+------------+--------------------+---------+-----+-----------+-------------+--------------+---------+------------+-------+--------------------+----------------+-----+\n",
      "|DAAmjNIonWZa9AMpO...|5V8eXkTJb6IejJkMD...|jXjglUcr2bDKdoV4l...|        2|2009-07-24|I went to Benjaro...|     3|    1|   1|jXjglUcr2bDKdoV4l...|\"Benjarong Thai R...|        null|\"1440 S Country C...|     Mesa|   AZ|      85210|   33.3889034|  -111.8403127|      3.5|          10|      0|    Restaurants;Thai|             2.0|    0|\n",
      "|DLT1Ypj7JtEM2JP_0...|PVyZXgOkVtnU6966F...|CAmPPSKoFCd8zo2bx...|        3|2015-12-29|Local greasy spoo...|     0|    0|   0|CAmPPSKoFCd8zo2bx...|\"Dino's Family Re...|        NoDa|\"350 E Sugar Cree...|Charlotte|   NC|      28213|    35.254686|    -80.793515|      3.5|          38|      1|Breakfast & Brunc...|             3.0|    0|\n",
      "|q9HTt8kCjHT01M3TF...|NKwPschAzbzzcS5UT...|gogO5RF4Rqz2THF1A...|        5|2016-04-27|Wonderful food an...|     0|    0|   0|gogO5RF4Rqz2THF1A...|\"Kabuki Japanese ...|        null|\"6770 N Sunrise B...| Glendale|   AZ|      85305|33.5339543188|-112.261047363|      3.5|         406|      1|Japanese;Restaura...|             5.0|    1|\n",
      "|YW73Swn6FIjPqtbhh...|vHF1sym4V_FkXbj-K...|gogO5RF4Rqz2THF1A...|        2|2016-03-08|There's not a lot...|     0|    0|   0|gogO5RF4Rqz2THF1A...|\"Kabuki Japanese ...|        null|\"6770 N Sunrise B...| Glendale|   AZ|      85305|33.5339543188|-112.261047363|      3.5|         406|      1|Japanese;Restaura...|             2.0|    0|\n",
      "|GR5lrrRssrisKOfoF...|JJTSeASs-VsDQos_0...|CAmPPSKoFCd8zo2bx...|        1|2015-06-21|Nasty food the se...|     0|    0|   0|CAmPPSKoFCd8zo2bx...|\"Dino's Family Re...|        NoDa|\"350 E Sugar Cree...|Charlotte|   NC|      28213|    35.254686|    -80.793515|      3.5|          38|      1|Breakfast & Brunc...|             1.0|    0|\n",
      "+--------------------+--------------------+--------------------+---------+----------+--------------------+------+-----+----+--------------------+--------------------+------------+--------------------+---------+-----+-----------+-------------+--------------+---------+------------+-------+--------------------+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fin1 = fin1.withColumn(\"label\", expr(\"case when stars_rev_double = 4 then 1 \" +\"when stars_rev_double = 5 then 1 \" +\"else 0 end \"))\n",
    "fin1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b100b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|This is currently...|    1|\n",
      "|This place is awe...|    1|\n",
      "|Atmosphere for th...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\"case when stars = 4 then 1 \" +\"when stars = 5 then 1 \" +\"else 0 end \"\n",
    "#df = df.withColumn(\"label\", df[\"stars\"].cast(\"double\"))\n",
    "\n",
    "df = fin1.select('text', 'label')\n",
    "df.show(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aab1461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|    1|      136894|\n",
      "|    0|       81573|\n",
      "+-----+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"reviews\")\n",
    "spark.sql(\"select label,count(label) from reviews group by label\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bcb8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.na.drop(how=\"any\")\n",
    "df1.createOrReplaceTempView(\"final_df_nonull\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7af4f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_len(text):\n",
    "    return len(text.split(' '))\n",
    "\n",
    "len_udf = udf(text_len, IntegerType())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c453059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-- Happy , 0-- Unhappy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|    1|      136863|\n",
      "|    0|       81549|\n",
      "+-----+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1 = df1.withColumn('review_len',len_udf('text'))\n",
    "df1 = df1.filter(df1.review_len > 2)\n",
    "\n",
    "print(\"1-- Happy , 0-- Unhappy\")\n",
    "df1.createOrReplaceTempView(\"df_nonull\")\n",
    "spark.sql(\"select label,count(label) from df_nonull  group by label\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1eb25bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean_text(string1):\n",
    "    string1 = string1.lower()\n",
    "    regex=re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct=regex.sub(\" \",string1)\n",
    "    #pattern=r'[0-9]'\n",
    "    #text=re.sub(pattern,'',nopunct)\n",
    "    return nopunct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d4a162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_text1=func.udf(lambda x: clean_text(x))\n",
    "yelp_df=df1.select('text','label',split_text1('text'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16a27b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+\n",
      "|                text|label|      <lambda>(text)|               words|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "|This is currently...|    1|this is currently...|[this, is, curren...|\n",
      "|This place is awe...|    1|this place is awe...|[this, place, is,...|\n",
      "|Atmosphere for th...|    0|atmosphere for th...|[atmosphere, for,...|\n",
      "|Great Japanese re...|    1|great japanese re...|[great, japanese,...|\n",
      "|Cute little hole ...|    1|cute little hole ...|[cute, little, ho...|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 25:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\",outputCol=\"words\")\n",
    "review_tokenized =tokenizer.transform(yelp_df)\n",
    "#review_tokenized.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37ecca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_rm = StopWordsRemover(inputCol='words',outputCol='words_new')\n",
    "review_tokenized = stopword_rm.transform(review_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d6cd963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|label|      <lambda>(text)|               words|           words_new|               tfidf|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|This is currently...|    1|this is currently...|[this, is, curren...|[currently, paren...|(262144,[0,1,18,2...|\n",
      "|This place is awe...|    1|this place is awe...|[this, place, is,...|[place, awesome!,...|(262144,[0,2,7,15...|\n",
      "|Atmosphere for th...|    0|atmosphere for th...|[atmosphere, for,...|[atmosphere, rest...|(262144,[0,3,7,9,...|\n",
      "|Great Japanese re...|    1|great japanese re...|[great, japanese,...|[great, japanese,...|(262144,[0,1,3,6,...|\n",
      "|Cute little hole ...|    1|cute little hole ...|[cute, little, ho...|[cute, little, ho...|(262144,[0,3,7,12...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(inputCol='words_new',outputCol='tfidf')\n",
    "cvModel=cv.fit(review_tokenized)\n",
    "count_vectorized=cvModel.transform(review_tokenized)\n",
    "count_vectorized.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba9b902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|label|      <lambda>(text)|               words|           words_new|               tfidf|                  tf|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|This is currently...|    1|this is currently...|[this, is, curren...|[currently, paren...|(262144,[0,1,18,2...|(262144,[0,1,18,2...|\n",
      "|This place is awe...|    1|this place is awe...|[this, place, is,...|[place, awesome!,...|(262144,[0,2,7,15...|(262144,[0,2,7,15...|\n",
      "|Atmosphere for th...|    0|atmosphere for th...|[atmosphere, for,...|[atmosphere, rest...|(262144,[0,3,7,9,...|(262144,[0,3,7,9,...|\n",
      "|Great Japanese re...|    1|great japanese re...|[great, japanese,...|[great, japanese,...|(262144,[0,1,3,6,...|(262144,[0,1,3,6,...|\n",
      "|Cute little hole ...|    1|cute little hole ...|[cute, little, ho...|[cute, little, ho...|(262144,[0,3,7,12...|(262144,[0,3,7,12...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 41:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "idf =IDF().setInputCol('tfidf').setOutputCol('tf')\n",
    "tfidfModel=idf.fit(count_vectorized)\n",
    "tfidf_df =tfidfModel.transform(count_vectorized)\n",
    "tfidf_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92e8455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = tfidf_df.select(['tfidf', 'label']).randomSplit([0.8,0.2],seed=42)\n",
    "train = splits[0].cache()\n",
    "test = splits[1].cache()\n",
    "train=train.withColumn(\"label\",train.label.cast(\"int\"))\n",
    "test=test.withColumn(\"label\",test.label.cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b939fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[184] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df.filter(df.label.isin(1.0,5.0))\n",
    "\n",
    "#df.write.csv(\"yelp-cleaned\")\n",
    "\n",
    "\n",
    "train_lb = train.rdd.map(lambda row: LabeledPoint(row[1], MLLibVectors.fromML(row[0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1f44873",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lb = test.rdd.map(lambda row: LabeledPoint(row[1], MLLibVectors.fromML(row[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e28d137f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Logistic Regression------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"----------Logistic Regression------\")\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr= LogisticRegression(featuresCol ='tfidf',labelCol='label',maxIter=20,regParam=0.3,elasticNetParam=0.8)\n",
    "lr_model=lr.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b37c4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|               tfidf|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(262144,[0,1,2,3,...|    1|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[-0.5175591617344...|[0.37342316021035...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions=lr_model.transform(test)\n",
    "predictions.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbc8360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 47:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy ::  0.6268299356957177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "acc_eval= MulticlassClassificationEvaluator(labelCol=\"label\",predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "acc_eval_lr=acc_eval.evaluate(predictions)\n",
    "print(\"Logistic Regression Accuracy :: \",acc_eval_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65745bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Random Forest Accuracy-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#RondomForest\n",
    "print(\"------Random Forest Accuracy-----\")\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol = 'tfidf', labelCol = 'label')\n",
    "rfModel = rf.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a81ab82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|               tfidf|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(262144,[0,1,2,3,...|    1|[7.55842142697927...|[0.37792107134896...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[8.97593303801791...|[0.44879665190089...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[8.86269302453433...|[0.44313465122671...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[7.47283423125702...|[0.37364171156285...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[7.79448648358644...|[0.38972432417932...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[7.36709239330246...|[0.36835461966512...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[8.89527807823118...|[0.44476390391155...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[7.33164692800473...|[0.36658234640023...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[9.02387458553125...|[0.45119372927656...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[8.66591662713313...|[0.43329583135665...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[8.68331527076235...|[0.43416576353811...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[8.18266119446997...|[0.40913305972349...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[7.89220707470683...|[0.39461035373534...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[8.40932263146404...|[0.42046613157320...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[7.85436225824353...|[0.39271811291217...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[8.48548468504620...|[0.42427423425231...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[8.72617974253304...|[0.43630898712665...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[7.90018147349322...|[0.39500907367466...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    1|[8.98317617123118...|[0.44915880856155...|       1.0|\n",
      "|(262144,[0,1,2,3,...|    0|[8.96708324311577...|[0.44835416215578...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rfModel.transform(test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cc463c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 67:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy ::  0.6273544032471382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "acc_eval_rf=acc_eval.evaluate(predictions)\n",
    "print(\"Random Forest Accuracy :: \",acc_eval_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d6f67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
