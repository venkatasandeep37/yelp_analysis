{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe7ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2dd87b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, StopWordsRemover\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, when, lit, month, year, to_date\n",
    "from pyspark.sql.types import StringType, DateType\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30213b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/27 22:29:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/11/27 22:29:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/11/27 22:29:57 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/11/27 22:29:57 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/11/27 22:29:57 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf = conf)\n",
    "spark = SparkSession(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "300314db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/27 22:30:13 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "## creating sparksession and giving an app name\n",
    "spark = SparkSession(sc).builder.appName('sparkdf').getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90040451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_rating = spark.read.csv('yelp_review.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a00e7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_rating = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"multiline\",\"true\").option('inferSchema', 'true').load('yelp_review.csv')#df.show(3)\n",
    "#print(df_rating.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94fc019e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+----------+--------------------+------+-----+----+\n",
      "|           review_id|             user_id|         business_id|stars|      date|                text|useful|funny|cool|\n",
      "+--------------------+--------------------+--------------------+-----+----------+--------------------+------+-----+----+\n",
      "|vkVSCC7xljjrAI4UG...|bv2nCi5Qv5vroFiqK...|AEx2SYEUJmTxVVB18...|    5|2016-05-28|Super simple plac...|     0|    0|   0|\n",
      "|n6QzIUObkYshz4dz2...|bv2nCi5Qv5vroFiqK...|VR6GpWIda3SfvPC-l...|    5|2016-05-28|Small unassuming ...|     0|    0|   0|\n",
      "|MV3CcKScW05u5LVfF...|bv2nCi5Qv5vroFiqK...|CKC0-MOWMqoeWf6s-...|    5|2016-05-28|Lester's is locat...|     0|    0|   0|\n",
      "+--------------------+--------------------+--------------------+-----+----------+--------------------+------+-----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rating.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0c9f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: string (nullable = true)\n",
      " |-- funny: string (nullable = true)\n",
      " |-- cool: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_rating.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d839e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_clean(df):\n",
    "    list = [1.0,2.0,3.0,4.0,5.0]\n",
    "    stopwords_remover = StopWordsRemover(inputCol = 'text', outputCol = 'text_wsw')\n",
    "    df = df.withColumn('date_format', df['date'].cast(DateType()))\n",
    "    df = df.withColumn('label', df['stars'].cast('double'))\n",
    "    df = df.filter(df.label.isin(list))\n",
    "    df = df.dropna(subset = ['text', 'label'])\n",
    "    df = df.withColumn(\"rating_class\",when((df.label == 5.0) | (df.label == 4.0), lit(\"satisfied\"))\\\n",
    "            .otherwise(lit(\"not satisfied\")))\n",
    "\n",
    "    return df\n",
    "\n",
    "def space_remove(x):\n",
    "    remove = [word for word in x if word != '']\n",
    "    return remove\n",
    "\n",
    "import re\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "stopword_list = ['under', 'hasn', 'an', 'how', 'aren', 'did', 'out', 'place', 'him', 'of', 'its', 'were', 'they', 'doing', \"it's\", 'if', \"you'd\", 'there', \"shouldn't\", 'should', 'not', 'from', 'is', 'because', 'or', 'you', 'get', 'too', 'her', 'before', 'once', 'most', 'shan', 'hers', 'these', 'had', 'again', \"you'll\", 'here', 'y', 'was', 'where', 'themselves', 'some', \"couldn't\", \"hasn't\", 'more', 'couldn', 'his', 'needn', 'their', 'having', 'and', 'myself', \"you've\", 'been', 'all', 'own', 've', 'ma', 'isn', 'further', \"didn't\", 'it', 'doesn', 'yourselves', 'other', 'he', \"that'll\", 'but', \"you're\", 'why', 'nor', 'only', 'no', 'while', 'me', 'very', \"don't\", 'ain', 'a', 'the', 'she', \"weren't\", \"shan't\", 'really', 'above', 'haven', \"should've\", 'off', \"wouldn't\", 'any', 'this', \"mightn't\", 'wasn', 'be', 'yours', 'into', 'in', 'so', 'as', 'd', 're', 'then', 'will', 'wouldn', 'weren', 'm', 'when', 'being', 'to', 'same', 'your', 'ourselves', 'now', 'herself', 'have', 'through', 'that', 'at', \"wasn't\", 'my', \"she's\", 'what', 'after', 'shouldn', 'about', 'few', 'has', \"haven't\", 'won', 'hadn', 'until', \"mustn't\", 'food', 'during', 'up', 'for', \"hadn't\", 'which', 'than', 'below', 'like', 'both', 'i', 'mightn', 'each', 'himself', \"doesn't\", 'does', 'theirs', 'don', 'am', \"isn't\", 'against', 'we', 't', 'yourself', 'with', 'down', 'mustn', 'who', 'do', 'just', 'ours', 'them', \"needn't\", 'are', 'on', 'such', 'those', 'itself', 'whom', 'our', 's', 'll', 'can', 'o', \"aren't\", 'one', 'between', 'didn', 'by', \"won't\", 'over']\n",
    "\n",
    "not_stopword = ['place', 'food','like', 'one', 'really', 'get']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24909ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rdd(rdd):\n",
    "    return rdd.map(lambda x: (re.sub('\\W+',' ', x[0]), x[1]))\\\n",
    "            .map(lambda x: ( x[0].lower().split(' '), x[1]))\\\n",
    "            .map(lambda x: (space_remove(x[0]), x[1]))\\\n",
    "            .map(lambda x: ([word for word in x[0] if word not in stopword_list], x[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8548d443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review  = dataframe_clean(df_rating).limit(5000).select('business_id', 'text', 'date_format','label','rating_class','date')\n",
    "#df_review.show(5)\n",
    "#df_review.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a542d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+-----+------------+----------+\n",
      "|         business_id|                text|date_format|label|rating_class|      date|\n",
      "+--------------------+--------------------+-----------+-----+------------+----------+\n",
      "|AEx2SYEUJmTxVVB18...|Super simple plac...| 2016-05-28|  5.0|   satisfied|2016-05-28|\n",
      "|VR6GpWIda3SfvPC-l...|Small unassuming ...| 2016-05-28|  5.0|   satisfied|2016-05-28|\n",
      "|CKC0-MOWMqoeWf6s-...|Lester's is locat...| 2016-05-28|  5.0|   satisfied|2016-05-28|\n",
      "|ACFtxLv8pGrrxMm6E...|Love coming here....| 2016-05-28|  4.0|   satisfied|2016-05-28|\n",
      "|s2I_Ni76bjJNK9yG6...|Had their chocola...| 2016-05-28|  4.0|   satisfied|2016-05-28|\n",
      "+--------------------+--------------------+-----------+-----+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_review.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2965f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the clean RDD\n",
    "rdd_base =  df_review.select('text', 'label',\"rating_class\").rdd.map(lambda x: (x[0],x[1]))\n",
    "rdd_base_clean = clean_rdd(rdd_base)\n",
    "#print(f'\\n{rdd_base_clean.collect()[:5]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bf9811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Find the distribution of reviews based on ratings/group using RDD\n",
    "\n",
    "rdd_Q1 = rdd_base_clean.map(lambda x: (x[1],1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "#print(f'\\nDistribution of reviews based on rating is: \\n{rdd_Q1.collect()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6528d5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of reviews based on rating is: \n",
      "[(5.0, 1608), (4.0, 1608), (3.0, 938), (1.0, 398), (2.0, 448)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f'\\nDistribution of reviews based on rating is: \\n{rdd_Q1.collect()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75aff327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the average of comment's length for each rating is: \n",
      "[(5.0, 53.132462686567166), (4.0, 59.12624378109453), (3.0, 66.30063965884861), (1.0, 64.88442211055276), (2.0, 67.05803571428571)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### 2.Find the average length of the comments for each rating /group\n",
    "\n",
    "rdd_Q2 = rdd_base_clean.map(lambda x: (x[1],len(x[0])))\\\n",
    "        .mapValues(lambda x: (x,1)).reduceByKey(lambda x,y: (x[0]+y[0],x[1]+y[1]))\\\n",
    "        .map(lambda x: (x[0], x[1][0]/x[1][1]))\n",
    "print(f\"\\nthe average of comment's length for each rating is: \\n{rdd_Q2.collect()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11a29eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Top 10 frequent words for 1.0 rating are:            # [('would', 205), ('service', 164), ('time', 160), ('back', 157), ('go', 147), ('us', 137), ('even', 126), ('never', 119), ('minutes', 109), ('said', 108)]\n",
      "\n",
      "The Top 10 frequent words for 2.0 rating are:            # [('good', 232), ('would', 195), ('time', 181), ('service', 151), ('back', 148), ('ordered', 144), ('go', 124), ('got', 117), ('also', 111), ('people', 101)]\n",
      "\n",
      "The Top 10 frequent words for 3.0 rating are:            # [('good', 631), ('would', 348), ('time', 339), ('service', 297), ('go', 274), ('great', 270), ('also', 260), ('pretty', 251), ('little', 249), ('de', 245)]\n",
      "\n",
      "The Top 10 frequent words for 4.0 rating are:            # [('good', 1025), ('great', 683), ('time', 546), ('also', 486), ('would', 439), ('service', 424), ('go', 419), ('nice', 403), ('back', 395), ('little', 376)]\n",
      "\n",
      "The Top 10 frequent words for 5.0 rating are:            # [('great', 819), ('good', 552), ('time', 519), ('go', 452), ('also', 438), ('service', 428), ('love', 417), ('back', 412), ('well', 402), ('always', 380)]\n"
     ]
    }
   ],
   "source": [
    "### 3. Find the frequent words (top 10) used in posting a review for each rating/group\n",
    "def word_couple(x):\n",
    "    result = []\n",
    "    for i in x:\n",
    "        result.append((i,1))\n",
    "    return result\n",
    "rdd_Q3 = rdd_base_clean.map(lambda x: (x[1],word_couple(x[0]))).reduceByKey(lambda x,y: x+y).sortByKey()\n",
    "\n",
    "for elt in rdd_Q3.collect():\n",
    "    list = [1.0,2.0,3.0,4.0,5.0]\n",
    "    freq = sc.parallelize(elt[1]).reduceByKey(lambda x,y: x + y)\n",
    "    print(f'\\nThe Top 10 frequent words for {elt[0]} rating are: \\\n",
    "           # {sorted(freq.collect(), key = lambda x:x[1], reverse = True)[:10]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b2f0bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 33:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 business with the most reviews are : [('Mexican;Restaurants', 94), ('Coffee & Tea;Food', 33), ('Food;Coffee & Tea', 27), ('Restaurants;Pizza', 18), ('Pizza;Restaurants', 17), ('Chinese;Restaurants', 16), ('Restaurants;Italian', 16), ('Italian;Restaurants', 14), ('Restaurants;Burgers', 14), ('Cinema;Arts & Entertainment', 14)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 33:=======>                                                  (1 + 7) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### 4. Find which business got most reviews after joining yelp_reviews with yelp_business\n",
    "\n",
    "df_business = spark.read.csv('yelp_business.csv', header = True)\n",
    "df_business = df_business.filter(~df_business.categories.isin(['0','1']))\n",
    "\n",
    "# join dataset 'yelp_reviews' and 'yelp_business'\n",
    "df_join1 = df_review.join(df_business, df_rating.business_id == df_business.business_id, 'inner')\n",
    "df_join1 = df_join1.withColumn(\"categories\",when(df_join1.categories == 'Restaurants;Mexican'\\\n",
    "        , lit('Mexican;Restaurants'))\n",
    "        .otherwise(df_join1.categories))\n",
    "\n",
    "rdd_cat_rating = df_join1.select('text', 'label', \"categories\")\\\n",
    "        .rdd.map(lambda x: (x[2],1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "print('Top 10 business with the most reviews are : %s'%sorted(rdd_cat_rating.collect()\\\n",
    "        , key = lambda x:x[1], reverse = True)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7911c512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The categories with the most rating 1.0 is:            [(('Mexican;Restaurants', 1.0), 12), (('Active Life;Golf', 1.0), 4), (('Home Services;Apartments;Real Estate', 1.0), 4), (('Restaurants;Pizza', 1.0), 4), (('Restaurants;Italian', 1.0), 3), (('Restaurants;Pizza;Italian;Sandwiches', 1.0), 2), (('Arts & Entertainment;Cinema', 1.0), 2), (('Hotels & Travel;Hotels;Event Planning & Services', 1.0), 2), (('Restaurants;Barbeque', 1.0), 2), (('Shopping Centers;Shopping', 1.0), 2)]\n",
      "\n",
      "The categories with the most rating 2.0 is:            [(('Mexican;Restaurants', 2.0), 10), (('Chinese;Restaurants', 2.0), 4), (('Food;Coffee & Tea', 2.0), 3), (('Coffee & Tea;Food', 2.0), 3), (('Vietnamese;Restaurants', 2.0), 3), ((\"Shopping;Fashion;Men's Clothing\", 2.0), 2), (('Bakeries;Food', 2.0), 2), (('Burgers;Fast Food;Restaurants', 2.0), 2), (('Sports Bars;American (Traditional);Restaurants;Bars;Nightlife', 2.0), 2), (('Comfort Food;Restaurants;Steakhouses;American (New)', 2.0), 2)]\n",
      "\n",
      "The categories with the most rating 3.0 is:            [(('Mexican;Restaurants', 3.0), 15), (('Food;Coffee & Tea', 3.0), 7), (('Coffee & Tea;Food', 3.0), 7), (('Restaurants;Burgers', 3.0), 5), (('Chinese;Restaurants', 3.0), 5), (('Restaurants;Italian', 3.0), 4), (('Bars;Nightlife', 3.0), 4), (('Restaurants;Chinese', 3.0), 4), (('Pizza;Restaurants;Italian', 3.0), 3), (('Restaurants;Burgers;Fast Food', 3.0), 3)]\n",
      "\n",
      "The categories with the most rating 4.0 is:            [(('Mexican;Restaurants', 4.0), 31), (('Coffee & Tea;Food', 4.0), 13), (('Restaurants;Chinese', 4.0), 7), (('Food;Coffee & Tea', 4.0), 7), (('Chinese;Restaurants', 4.0), 6), (('Restaurants;Pizza', 4.0), 6), (('Grocery;Food', 4.0), 5), (('Cinema;Arts & Entertainment', 4.0), 5), (('Restaurants;Japanese;Sushi Bars', 4.0), 5), (('Pizza;Restaurants', 4.0), 5)]\n",
      "\n",
      "The categories with the most rating 5.0 is:            [(('Mexican;Restaurants', 5.0), 26), (('Food;Coffee & Tea', 5.0), 9), (('Coffee & Tea;Food', 5.0), 9), (('Pizza;Restaurants', 5.0), 7), (('Italian;Restaurants', 5.0), 6), (('Food;Ice Cream & Frozen Yogurt', 5.0), 5), (('Hiking;Active Life', 5.0), 5), (('Cinema;Arts & Entertainment', 5.0), 5), (('Arts & Entertainment;Cinema', 5.0), 5), (('Restaurants;Pizza', 5.0), 4)]\n"
     ]
    }
   ],
   "source": [
    "### 5. Find which business got most 5-star rating and find the which business got most 4-star rating so on\n",
    "\n",
    "rdd_cat = df_join1.select('text', 'label', 'categories').rdd.\\\n",
    "        map(lambda x: ((x[2],x[1]),1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "list = [1.0,2.0,3.0,4.0,5.0]\n",
    "for a in list:\n",
    "    rdd_inter = rdd_cat.filter(lambda x: x[0][1] == a)\n",
    "    print(f'\\nThe categories with the most rating {a} is:\\\n",
    "            {sorted(rdd_inter.collect(), key = lambda x: (x[0][1], x[1]), reverse = True)[:10]}')\n",
    "\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "deaaeb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2016-05-28', 5, 2016), ('2016-05-28', 5, 2016), ('2016-05-28', 5, 2016), ('2016-05-28', 5, 2016), ('2016-05-28', 5, 2016), ('2014-09-24', 9, 2014), ('2012-05-11', 5, 2012), ('2015-10-27', 10, 2015), ('2013-02-09', 2, 2013), ('2016-04-06', 4, 2016)]\n",
      "[(2016, 801), (2014, 792), (2012, 331), (2015, 803), (2013, 664), (2011, 401), (2010, 222), (2017, 719), (2009, 111), (2008, 28)]\n"
     ]
    }
   ],
   "source": [
    "### 6.Find the average monthly/yearly review count in yelp system\n",
    "\n",
    "# change date type in the review dataframe => see function 'dataframe_clean'\n",
    "# create new variable month and year\n",
    "\n",
    "rdd_ym = df_review.select(col('date'), col('business_id'), month(col(\"date\")).alias(\"month\"), year(col(\"date\")).alias(\"year\")).rdd.map(lambda x: (x[0],x[2], x[3]))\n",
    "print(rdd_ym.collect()[:10])\n",
    "\n",
    "#rdd_m = \n",
    "rdd_y = rdd_ym. map(lambda x: (x[2],1)).reduceByKey(lambda x,y : x+y)\n",
    "print(rdd_y.collect()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7bf7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
